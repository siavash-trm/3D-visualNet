{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Importing essential libraries\n\nimport numpy as np\nimport PIL\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport os\nimport glob\nimport cv2\nfrom pathlib import Path\nimport keras\nimport tensorflow_datasets as tfds\nfrom keras import layers\nfrom keras import regularizers\nfrom keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization , Input , Reshape\nfrom keras.models import Model\nfrom sklearn.model_selection import train_test_split\nimport re\nfrom tensorflow.keras.layers import Rescaling \nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import get_custom_objects\nfrom tensorflow.keras.callbacks import EarlyStopping\n!pip install nibabel  \nfrom tqdm import tqdm\nimport nibabel as nib\nfrom scipy.ndimage import zoom\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.utils import plot_model\nfrom sklearn.utils.class_weight import compute_class_weight\n\n\n\n\n#Utilizing both GPUs simultaneously\n\n!nvidia-smi\nstrategy = tf.distribute.MirroredStrategy([\"GPU:0\", \"GPU:1\"])\nprint(f\"Number of GPUs Available: {strategy.num_replicas_in_sync}\")\n\n\n\n\n\n# Defining  functions for sorting the image files and mask files in a specific order \n\ndef natural_sort(item):\n    return [int(text) if text.isdigit() else text.lower() for text in re.split(r'(\\d+)', item)]\n\n\n\ndef extract_id(path):\n    basename = os.path.basename(path)\n    match = re.search(r'PatientID_\\d+', basename)  \n    return match.group() if match else None\n\n\n\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-02T14:33:44.098414Z","iopub.execute_input":"2025-06-02T14:33:44.098670Z","iopub.status.idle":"2025-06-02T14:34:05.526220Z","shell.execute_reply.started":"2025-06-02T14:33:44.098651Z","shell.execute_reply":"2025-06-02T14:34:05.525338Z"}},"outputs":[{"name":"stderr","text":"2025-06-02 14:33:45.734578: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1748874825.956139      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1748874826.021968      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: nibabel in /usr/local/lib/python3.11/dist-packages (5.3.2)\nRequirement already satisfied: importlib-resources>=5.12 in /usr/local/lib/python3.11/dist-packages (from nibabel) (6.5.2)\nRequirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.11/dist-packages (from nibabel) (1.26.4)\nRequirement already satisfied: packaging>=20 in /usr/local/lib/python3.11/dist-packages (from nibabel) (25.0)\nRequirement already satisfied: typing-extensions>=4.6 in /usr/local/lib/python3.11/dist-packages (from nibabel) (4.13.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22->nibabel) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22->nibabel) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22->nibabel) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22->nibabel) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22->nibabel) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22->nibabel) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.22->nibabel) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.22->nibabel) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.22->nibabel) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.22->nibabel) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.22->nibabel) (2024.2.0)\nMon Jun  2 14:34:03 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   41C    P8              9W /   70W |       1MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   43C    P8              9W /   70W |       1MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\nNumber of GPUs Available: 2\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1748874845.484217      35 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1748874845.484879      35 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"}],"execution_count":1}]}